{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE THE ATTENTION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the model to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import attention_models\n",
    "import better_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"model_train_70_val_68\" #\"attention_data/model_2_train_76_val_68\"\n",
    "max_sequence_length = 283\n",
    "\n",
    "model = better_attention_models.MyAttentionModelWithPoolingBatchNormSkip(vocab_size=len(voc), embedding_dim=64, max_seq_len=max_sequence_length, num_heads=4, dim_feedforward=16, num_layers=1, dropout=0.5).to(device)\n",
    "#attention_models.MyAttentionModelWithMaskOnWordPositionOutputAndMaskedSkipCORRECTEDwithMaskOnPaddingBothWaysTransposed(vocab_size=len(voc), embedding_dim=8, max_seq_len=max_sequence_length, num_heads=2, dim_feedforward=8, num_layers=1, dropout=0.1)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the data to evaluate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import help_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file():\n",
    "    should_load = input(\"Do you wish to load data from a file? (y/n): \")\n",
    "    if should_load == \"y\":\n",
    "        filename = input(\"Specify the filename to load from: \")\n",
    "        data = pd.read_csv(filename)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(filename):\n",
    "    with open(filename, \"rb\") as load_file:\n",
    "        return pickle.load(load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = load_pickle_data(\"/home/lovhag/storage/data/attention_data/_voc.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_indices = train_test_split(range(2*len(data)), test_size=0.33, random_state=42)\n",
    "test_indices = [index/2 for index in test_indices if index % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word_pos</th>\n",
       "      <th>sense_key</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>sensed_lemma</th>\n",
       "      <th>sense_encoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>Article 4 of the Constitution stipulates that ...</td>\n",
       "      <td>case.n</td>\n",
       "      <td>36</td>\n",
       "      <td>case%1:04:00::</td>\n",
       "      <td>article 4 of the Constitution stipulate that :...</td>\n",
       "      <td>case_5</td>\n",
       "      <td>article 4 of the Constitution stipulate that :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67883</th>\n",
       "      <td>The keynotes of this style are activism and em...</td>\n",
       "      <td>major.a</td>\n",
       "      <td>61</td>\n",
       "      <td>major%3:00:01::</td>\n",
       "      <td>the keynote of this style be activism and emph...</td>\n",
       "      <td>major_1</td>\n",
       "      <td>the keynote of this style be activism and emph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>The State party should ensure that counter-ter...</td>\n",
       "      <td>life.n</td>\n",
       "      <td>60</td>\n",
       "      <td>life%1:28:02::</td>\n",
       "      <td>the State party should ensure that counter-ter...</td>\n",
       "      <td>life_5</td>\n",
       "      <td>the State party should ensure that counter-ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71501</th>\n",
       "      <td>Already in its general comment No . 4 on the r...</td>\n",
       "      <td>security.n</td>\n",
       "      <td>92</td>\n",
       "      <td>security%1:21:01::</td>\n",
       "      <td>already in -PRON- general comment no . 4 on th...</td>\n",
       "      <td>security_5</td>\n",
       "      <td>already in -PRON- general comment no . 4 on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39417</th>\n",
       "      <td>The subsidiary bodies of the Commission on Nar...</td>\n",
       "      <td>lead.v</td>\n",
       "      <td>69</td>\n",
       "      <td>lead%2:41:12::</td>\n",
       "      <td>the subsidiary body of the Commission on Narco...</td>\n",
       "      <td>lead_7</td>\n",
       "      <td>the subsidiary body of the Commission on Narco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text       lemma  \\\n",
       "4660   Article 4 of the Constitution stipulates that ...      case.n   \n",
       "67883  The keynotes of this style are activism and em...     major.a   \n",
       "10751  The State party should ensure that counter-ter...      life.n   \n",
       "71501  Already in its general comment No . 4 on the r...  security.n   \n",
       "39417  The subsidiary bodies of the Commission on Nar...      lead.v   \n",
       "\n",
       "       word_pos           sense_key  \\\n",
       "4660         36      case%1:04:00::   \n",
       "67883        61     major%3:00:01::   \n",
       "10751        60      life%1:28:02::   \n",
       "71501        92  security%1:21:01::   \n",
       "39417        69      lead%2:41:12::   \n",
       "\n",
       "                                         lemmatized_text sensed_lemma  \\\n",
       "4660   article 4 of the Constitution stipulate that :...       case_5   \n",
       "67883  the keynote of this style be activism and emph...      major_1   \n",
       "10751  the State party should ensure that counter-ter...       life_5   \n",
       "71501  already in -PRON- general comment no . 4 on th...   security_5   \n",
       "39417  the subsidiary body of the Commission on Narco...       lead_7   \n",
       "\n",
       "                                      sense_encoded_text  \n",
       "4660   article 4 of the Constitution stipulate that :...  \n",
       "67883  the keynote of this style be activism and emph...  \n",
       "10751  the State party should ensure that counter-ter...  \n",
       "71501  already in -PRON- general comment no . 4 on th...  \n",
       "39417  the subsidiary body of the Commission on Narco...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data.iloc[test_indices].copy()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the State party should ensure that counter-terrorism measure be in full conformity with the Covenant and , in particular , that the legislation adopt in this context be limit to crime that would justify be assimilate to terrorism and attract the often grave consequence associate with -PRON- . -PRON- should allow for some degree of judicial discretion in sentence to life_5 imprisonment . the State party be also request to inform the Committee on whether the Terrorism Act have ever be apply .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.iloc[2].sense_encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequence, max_sequence_len):\n",
    "    return sequence+[voc.get_pad_idx()]*(max_sequence_len-len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = 283\n",
    "def create_eval_data_per_lemma(data, with_word_position_mask=True):\n",
    "    # create a dict over the data per lemma\n",
    "    # for a lemma, we have a list of dicts\n",
    "    # for a dict we have X_data containing several variations of the same sentence\n",
    "    # in the dict, we also have y_data, which contains one integer specifying the correct variation of the sentence\n",
    "    def build_X_elem(X):\n",
    "        X_elem = voc.encode([X])[0]\n",
    "        if max_sequence_len:\n",
    "            return pad_sequence(X_elem, max_sequence_len)\n",
    "        return X_elem\n",
    "\n",
    "    sense_dict = help_functions.build_sense_dict(data.lemma.to_list(), data.sense_key.to_list())\n",
    "    eval_data = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        X_data = []\n",
    "        y_data = []\n",
    "        if with_word_position_mask:\n",
    "            mask_data = []\n",
    "\n",
    "        X_data.append(build_X_elem(row.sense_encoded_text.split(\" \")))\n",
    "        y_data.append([0])\n",
    "\n",
    "        # append faulty sense examples\n",
    "        available_senses = list(sense_dict[row.lemma].keys())\n",
    "        available_senses.remove(row.sense_key)\n",
    "        for faulty_sense in available_senses:\n",
    "            faulty_text = row.sense_encoded_text.split(\" \")\n",
    "            faulty_text[row.word_pos] = row.lemma[:-2]+\"_\"+str(sense_dict[row.lemma][faulty_sense])\n",
    "            X_data.append(build_X_elem(faulty_text.copy()))\n",
    "\n",
    "        if with_word_position_mask:\n",
    "            mask_vec = [False]*max_sequence_len\n",
    "            mask_vec[row.word_pos+1] = True\n",
    "            for sense_num in range(len(available_senses)+1):\n",
    "                mask_data.append(mask_vec)\n",
    "\n",
    "        dict_entry = {\"X_data\": X_data, \"mask_data\": mask_data, \"y_data\": y_data}\n",
    "        if row.lemma in eval_data:\n",
    "            eval_data[row.lemma].append(dict_entry)\n",
    "        else:\n",
    "            eval_data[row.lemma] = [dict_entry]\n",
    "    \n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = create_eval_data_per_lemma(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[\"keep.v\"][2][\"y_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = load_pickle_data(\"/home/lovhag/storage/data/attention_data/_eval_data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define an evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_per_lemma(model, eval_data):\n",
    "    print(f\"Model evaluation started!\")\n",
    "    test_acc = {}\n",
    "    model.eval()\n",
    "    for lemma in eval_data.keys():\n",
    "        print(f\"Evaluating model for lemma {lemma}...\")\n",
    "        with torch.no_grad():\n",
    "            accuracy_sum = 0\n",
    "            nbr_test_samples = 0\n",
    "            for dict_entry in eval_data[lemma]:\n",
    "                nbr_test_samples += 1\n",
    "                output = model.forward(torch.LongTensor(dict_entry[\"X_data\"]).to(device), torch.BoolTensor(dict_entry[\"mask_data\"]).to(device))\n",
    "                #print(f\"output: {output.numpy().flatten()}\")\n",
    "                correct_index_guess = np.argmax(output.cpu().numpy().flatten())\n",
    "                #print(f\"correct index guess: {correct_index_guess}\")\n",
    "                #loss = loss_fun(output, by.type(torch.FloatTensor))\n",
    "                #loss_sum += loss.item()\n",
    "                accuracy = [1 if correct_index_guess==dict_entry[\"y_data\"][0] else 0]\n",
    "                #print(f\"accuracy: {accuracy}\")\n",
    "                accuracy_sum += accuracy[0]\n",
    "        #test_loss = loss_sum/(nbr_test_batches*batch_size)\n",
    "        #print(h)\n",
    "        test_acc[lemma] = accuracy_sum/nbr_test_samples\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Using', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation started!\n",
      "Evaluating model for lemma case.n...\n",
      "Evaluating model for lemma major.a...\n",
      "Evaluating model for lemma life.n...\n",
      "Evaluating model for lemma security.n...\n",
      "Evaluating model for lemma lead.v...\n",
      "Evaluating model for lemma extend.v...\n",
      "Evaluating model for lemma point.n...\n",
      "Evaluating model for lemma see.v...\n",
      "Evaluating model for lemma force.n...\n",
      "Evaluating model for lemma national.a...\n",
      "Evaluating model for lemma line.n...\n",
      "Evaluating model for lemma physical.a...\n",
      "Evaluating model for lemma regular.a...\n",
      "Evaluating model for lemma find.v...\n",
      "Evaluating model for lemma bad.a...\n",
      "Evaluating model for lemma positive.a...\n",
      "Evaluating model for lemma hold.v...\n",
      "Evaluating model for lemma professional.a...\n",
      "Evaluating model for lemma bring.v...\n",
      "Evaluating model for lemma serve.v...\n",
      "Evaluating model for lemma critical.a...\n",
      "Evaluating model for lemma common.a...\n",
      "Evaluating model for lemma keep.v...\n",
      "Evaluating model for lemma time.n...\n",
      "Evaluating model for lemma active.a...\n",
      "Evaluating model for lemma place.n...\n",
      "Evaluating model for lemma follow.v...\n",
      "Evaluating model for lemma order.n...\n",
      "Evaluating model for lemma build.v...\n",
      "Evaluating model for lemma position.n...\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_model_per_lemma(model, eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case.n': 0.23616734143049933,\n",
       " 'major.a': 0.5288065843621399,\n",
       " 'life.n': 0.2453900709219858,\n",
       " 'security.n': 0.32045779685264664,\n",
       " 'lead.v': 0.18457943925233644,\n",
       " 'extend.v': 0.41947565543071164,\n",
       " 'point.n': 0.5204402515723271,\n",
       " 'see.v': 0.6167747914735866,\n",
       " 'force.n': 0.1670428893905192,\n",
       " 'national.a': 0.24039829302987198,\n",
       " 'line.n': 0.8397849462365592,\n",
       " 'physical.a': 0.4570552147239264,\n",
       " 'regular.a': 0.20574886535552195,\n",
       " 'find.v': 0.2012820512820513,\n",
       " 'bad.a': 0.640625,\n",
       " 'positive.a': 0.5607940446650124,\n",
       " 'hold.v': 0.1586998087954111,\n",
       " 'professional.a': 0.3174846625766871,\n",
       " 'bring.v': 0.21385902031063322,\n",
       " 'serve.v': 0.1659877800407332,\n",
       " 'critical.a': 0.2955390334572491,\n",
       " 'common.a': 0.3488773747841105,\n",
       " 'keep.v': 0.3925438596491228,\n",
       " 'time.n': 0.26519337016574585,\n",
       " 'active.a': 0.3530701754385965,\n",
       " 'place.n': 0.296875,\n",
       " 'follow.v': 0.12401055408970976,\n",
       " 'order.n': 0.212481426448737,\n",
       " 'build.v': 0.17904993909866018,\n",
       " 'position.n': 0.31850789096126253}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3342334377265451"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_acc = sum(test_acc.values())/len(test_acc)\n",
    "mean_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case.n': 0.08232118758434548,\n",
       " 'major.a': 0.16049382716049382,\n",
       " 'life.n': 0.21560283687943263,\n",
       " 'security.n': 0.09585121602288985,\n",
       " 'lead.v': 0.03387850467289719,\n",
       " 'extend.v': 0.3096129837702871,\n",
       " 'point.n': 0.0660377358490566,\n",
       " 'see.v': 0.335032437442076,\n",
       " 'force.n': 0.07674943566591422,\n",
       " 'national.a': 0.11095305832147938,\n",
       " 'line.n': 0.8204301075268817,\n",
       " 'physical.a': 0.09815950920245399,\n",
       " 'regular.a': 0.09228441754916793,\n",
       " 'find.v': 0.1064102564102564,\n",
       " 'bad.a': 0.2760416666666667,\n",
       " 'positive.a': 0.07444168734491315,\n",
       " 'hold.v': 0.06309751434034416,\n",
       " 'professional.a': 0.18404907975460122,\n",
       " 'bring.v': 0.06332138590203107,\n",
       " 'serve.v': 0.03767820773930754,\n",
       " 'critical.a': 0.15613382899628253,\n",
       " 'common.a': 0.4542314335060449,\n",
       " 'keep.v': 0.1737938596491228,\n",
       " 'time.n': 0.09116022099447514,\n",
       " 'active.a': 0.14035087719298245,\n",
       " 'place.n': 0.1890625,\n",
       " 'follow.v': 0.13896218117854,\n",
       " 'order.n': 0.25705794947994054,\n",
       " 'build.v': 0.02679658952496955,\n",
       " 'position.n': 0.1649928263988522}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16983297742422357"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_acc = sum(test_acc.values())/len(test_acc)\n",
    "mean_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case.n': 0.22807017543859648,\n",
       " 'major.a': 0.294238683127572,\n",
       " 'life.n': 0.20851063829787234,\n",
       " 'security.n': 0.20457796852646637,\n",
       " 'lead.v': 0.17523364485981308,\n",
       " 'extend.v': 0.3620474406991261,\n",
       " 'point.n': 0.5849056603773585,\n",
       " 'see.v': 0.6167747914735866,\n",
       " 'force.n': 0.14672686230248308,\n",
       " 'national.a': 0.0,\n",
       " 'line.n': 0.8397849462365592,\n",
       " 'physical.a': 0.2254601226993865,\n",
       " 'regular.a': 0.4281391830559758,\n",
       " 'find.v': 0.0,\n",
       " 'bad.a': 0.59375,\n",
       " 'positive.a': 0.5682382133995038,\n",
       " 'hold.v': 0.1615678776290631,\n",
       " 'professional.a': 0.22392638036809817,\n",
       " 'bring.v': 0.17204301075268819,\n",
       " 'serve.v': 0.0,\n",
       " 'critical.a': 0.2843866171003718,\n",
       " 'common.a': 0.46459412780656306,\n",
       " 'keep.v': 0.3925438596491228,\n",
       " 'time.n': 0.26519337016574585,\n",
       " 'active.a': 0.30701754385964913,\n",
       " 'place.n': 0.240625,\n",
       " 'follow.v': 0.25241864555848725,\n",
       " 'order.n': 0.2213967310549777,\n",
       " 'build.v': 0.1656516443361754,\n",
       " 'position.n': 0.19655667144906744}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something to compare with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a48aed4c6448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msense_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelp_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_sense_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msense_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnbr_senses_per_lemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msense_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msense_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnbr_senses_per_lemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "sense_dict = help_functions.build_sense_dict(test_data.lemma.to_list(), test_data.sense_key.to_list())\n",
    "nbr_senses_per_lemma = {lemma: len(sense_dict[lemma]) for lemma in sense_dict.keys()}\n",
    "nbr_senses_per_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case.n': 0.125,\n",
       " 'major.a': 0.25,\n",
       " 'life.n': 0.1111111111111111,\n",
       " 'security.n': 0.14285714285714285,\n",
       " 'lead.v': 0.125,\n",
       " 'extend.v': 0.14285714285714285,\n",
       " 'point.n': 0.125,\n",
       " 'see.v': 0.09090909090909091,\n",
       " 'force.n': 0.125,\n",
       " 'national.a': 0.16666666666666666,\n",
       " 'line.n': 0.09090909090909091,\n",
       " 'physical.a': 0.16666666666666666,\n",
       " 'regular.a': 0.125,\n",
       " 'find.v': 0.1,\n",
       " 'bad.a': 0.25,\n",
       " 'positive.a': 0.2,\n",
       " 'hold.v': 0.09090909090909091,\n",
       " 'professional.a': 0.2,\n",
       " 'bring.v': 0.125,\n",
       " 'serve.v': 0.1111111111111111,\n",
       " 'critical.a': 0.2,\n",
       " 'common.a': 0.25,\n",
       " 'keep.v': 0.09090909090909091,\n",
       " 'time.n': 0.2,\n",
       " 'active.a': 0.2,\n",
       " 'place.n': 0.14285714285714285,\n",
       " 'follow.v': 0.09090909090909091,\n",
       " 'order.n': 0.2,\n",
       " 'build.v': 0.1,\n",
       " 'position.n': 0.16666666666666666}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_guessing_accuracy_per_lemma = {lemma: 1/nbr_senses_per_lemma[lemma] for lemma in sense_dict.keys()}\n",
    "random_guessing_accuracy_per_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean acc: 0.2941459936741436\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean acc: {np.sum([value for key, value in test_acc.items()])/len(test_acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>random_guess_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>case.n</th>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major.a</th>\n",
       "      <td>0.294239</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life.n</th>\n",
       "      <td>0.208511</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security.n</th>\n",
       "      <td>0.204578</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead.v</th>\n",
       "      <td>0.175234</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend.v</th>\n",
       "      <td>0.362047</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point.n</th>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see.v</th>\n",
       "      <td>0.616775</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force.n</th>\n",
       "      <td>0.146727</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national.a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.n</th>\n",
       "      <td>0.839785</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical.a</th>\n",
       "      <td>0.225460</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular.a</th>\n",
       "      <td>0.428139</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find.v</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad.a</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive.a</th>\n",
       "      <td>0.568238</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold.v</th>\n",
       "      <td>0.161568</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional.a</th>\n",
       "      <td>0.223926</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring.v</th>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve.v</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical.a</th>\n",
       "      <td>0.284387</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common.a</th>\n",
       "      <td>0.464594</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep.v</th>\n",
       "      <td>0.392544</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time.n</th>\n",
       "      <td>0.265193</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active.a</th>\n",
       "      <td>0.307018</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place.n</th>\n",
       "      <td>0.240625</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow.v</th>\n",
       "      <td>0.252419</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order.n</th>\n",
       "      <td>0.221397</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build.v</th>\n",
       "      <td>0.165652</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position.n</th>\n",
       "      <td>0.196557</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_acc  random_guess_acc\n",
       "case.n          0.228070          0.125000\n",
       "major.a         0.294239          0.250000\n",
       "life.n          0.208511          0.111111\n",
       "security.n      0.204578          0.142857\n",
       "lead.v          0.175234          0.125000\n",
       "extend.v        0.362047          0.142857\n",
       "point.n         0.584906          0.125000\n",
       "see.v           0.616775          0.090909\n",
       "force.n         0.146727          0.125000\n",
       "national.a      0.000000          0.166667\n",
       "line.n          0.839785          0.090909\n",
       "physical.a      0.225460          0.166667\n",
       "regular.a       0.428139          0.125000\n",
       "find.v          0.000000          0.100000\n",
       "bad.a           0.593750          0.250000\n",
       "positive.a      0.568238          0.200000\n",
       "hold.v          0.161568          0.090909\n",
       "professional.a  0.223926          0.200000\n",
       "bring.v         0.172043          0.125000\n",
       "serve.v         0.000000          0.111111\n",
       "critical.a      0.284387          0.200000\n",
       "common.a        0.464594          0.250000\n",
       "keep.v          0.392544          0.090909\n",
       "time.n          0.265193          0.200000\n",
       "active.a        0.307018          0.200000\n",
       "place.n         0.240625          0.142857\n",
       "follow.v        0.252419          0.090909\n",
       "order.n         0.221397          0.200000\n",
       "build.v         0.165652          0.100000\n",
       "position.n      0.196557          0.166667"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data = pd.DataFrame(data = [test_acc, random_guessing_accuracy_per_lemma]).transpose()\n",
    "result_data.rename(columns={0: \"test_acc\", 1: \"random_guess_acc\"}, inplace=True)\n",
    "result_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
