{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('dl4nlp_assignment_1': conda)",
   "display_name": "Python 3.8.5 64-bit ('dl4nlp_assignment_1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dfc50ec6eac23905ec9d0de14b95fb04de7a27191c56780f2104afc692b71c20"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# GET BERT DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "source": [
    "## CONTENT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. Create \"sense sentences\" for each available sense. The sentence should correctly make use of the sense.\n",
    "2. Create training samples, where each data sample generates two training samples. 1) sample where a sample is paired with a correct sense sentence, 2) where a sample is paired with an incorrect sense sentence.\n",
    "3. Save the data.\n",
    "\n",
    "### In another file\n",
    "4. Obtain a pre-trained BERT.\n",
    "5. Fine-tune BERT on the new data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Create sense sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            sense_key       lemma  word_position  \\\n",
       "0      keep%2:42:07::      keep.v             15   \n",
       "1  national%3:01:00::  national.a             25   \n",
       "2     build%2:31:03::     build.v             38   \n",
       "3     place%1:04:00::     place.n             36   \n",
       "4  position%1:04:01::  position.n             76   \n",
       "\n",
       "                                                text  \n",
       "0  Action by the Committee In pursuance of its ma...  \n",
       "1  A guard of honour stood in formation in honour...  \n",
       "2  The principle that statistics should be timely...  \n",
       "3  Again , he appealed for additional support for...  \n",
       "4  Also , the IAEA has the lowest number of women...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sense_key</th>\n      <th>lemma</th>\n      <th>word_position</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>keep%2:42:07::</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>Action by the Committee In pursuance of its ma...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>national%3:01:00::</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>A guard of honour stood in formation in honour...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>build%2:31:03::</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>The principle that statistics should be timely...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>place%1:04:00::</td>\n      <td>place.n</td>\n      <td>36</td>\n      <td>Again , he appealed for additional support for...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>position%1:04:01::</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>Also , the IAEA has the lowest number of women...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "filename = \"/Users/lovhag/Projects/dl4nlp_assignment_1/a1_data/wsd_train.txt\"\n",
    "data = pd.read_table(filename,header=None,names=['sense_key', 'lemma', 'word_position', 'text'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76049 entries, 0 to 76048\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   sense_key      76049 non-null  object\n 1   lemma          76049 non-null  object\n 2   word_position  76049 non-null  int64 \n 3   text           76049 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list = data.lemma.unique()\n",
    "sense_dict = {lemma: list(data[data.lemma==lemma].sense_key.unique()) for lemma in lemma_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of available senses: 222\n"
     ]
    }
   ],
   "source": [
    "total_nbr_of_senses = sum([len(sense_dict[key]) for key in sense_dict])\n",
    "print(f\"Total number of available senses: {total_nbr_of_senses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_per_sense = {sense: data[data.sense_key == sense].text.iloc[0] for sense in list(data.sense_key.unique())}\n",
    "sentence_per_lemma_sense = {lemma: {sense: data[data.sense_key == sense].text.iloc[0] for sense in list(data[data.lemma==lemma].sense_key.unique())} for lemma in list(data.lemma.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Action by the Committee In pursuance of its mandate , the Committee will continue to keep under review the situation relating to the question of Palestine and participate in relevant meetings of the General Assembly and the Security Council . The Committee will also continue to monitor the situation on the ground and draw the attention of the international community to urgent developments in the Occupied Palestinian Territory , including East Jerusalem , requiring international action .'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sentence_per_sense[\"keep%2:42:07::\"]"
   ]
  },
  {
   "source": [
    "## 2. Split into training and testing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(range(len(data)), test_size=.2, random_state=42)\n",
    "train_data = data.iloc[train_indices].copy()\n",
    "test_data = data.iloc[test_indices].copy()"
   ]
  },
  {
   "source": [
    "## 3. Create training samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_pair_data(data):\n",
    "    X_data_1 = [] # pairs!\n",
    "    X_data_2 = []\n",
    "    y_data = []\n",
    "    def add_data_entry(row, sense_key, label):\n",
    "        two_sentences = []\n",
    "        X_data_1.append(row.text)\n",
    "        X_data_2.append(sentence_per_lemma_sense[row.lemma][sense_key])\n",
    "        y_data.append(label)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        add_data_entry(row, row.sense_key, 1)\n",
    "\n",
    "        faulty_senses = list(sentence_per_lemma_sense[row.lemma].keys())\n",
    "        faulty_senses.remove(row.sense_key)\n",
    "        faulty_sense_key = np.random.choice(faulty_senses)\n",
    "        add_data_entry(row, faulty_sense_key, 0)\n",
    "    return X_data_1, X_data_2, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_1, X_data_2, y_data = create_sentence_pair_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'( vii ) BGL - General Trust Fund for the Core Programme Budget for the Biosafety Protocol , which is extended through 31 December 2011 ; ( viii ) BHL - Special Voluntary Trust Fund for Additional Voluntary Contributions in Support of Approved Activities of the Biosafety Protocol , which is extended through 31 December 2011 ; ( ix ) BTL - General Trust Fund for the Conservation of European Bats ( EUROBATS ) , which is extended through 31 December 2014 ;'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "X_data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of data samples for training: 121678\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data samples for training: {len(X_data_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_with_pickle(data_dict):\n",
    "    pre_filename = input(f\"Specify which prefix filename you wish to save {list(data_dict.keys())} to: \")\n",
    "    if pre_filename:\n",
    "        for key, value in data_dict.items():\n",
    "            filename = pre_filename+\"_\"+key+\".pickle\"\n",
    "            with open(filename, \"wb\") as fp:   #Pickling\n",
    "                pickle.dump(value, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"X_data_1_train\": X_data_1, \"X_data_2_train\": X_data_2, \"y_data_train\": y_data})"
   ]
  },
  {
   "source": [
    "## 4. Create testing samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of data samples for testing: 30420\n"
     ]
    }
   ],
   "source": [
    "X_data_1, X_data_2, y_data = create_sentence_pair_data(test_data)\n",
    "print(f\"Number of data samples for testing: {len(X_data_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"X_data_1_test\": X_data_1, \"X_data_2_test\": X_data_2, \"y_data_test\": y_data})"
   ]
  },
  {
   "source": [
    "### Create samples for evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_sentence_pair_data(data):\n",
    "    evaluation_data = {}\n",
    "    def add_data_entry(row, sense_key):\n",
    "        two_sentences = []\n",
    "        X_data_1.append(row.text)\n",
    "        X_data_2.append(sentence_per_lemma_sense[row.lemma][sense_key])\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        X_data_1 = [] # pairs!\n",
    "        X_data_2 = []\n",
    "        y_data = [0]\n",
    "\n",
    "        add_data_entry(row, row.sense_key)\n",
    "\n",
    "        faulty_senses = list(sentence_per_lemma_sense[row.lemma].keys())\n",
    "        faulty_senses.remove(row.sense_key)\n",
    "        for faulty_sense_key in faulty_senses:\n",
    "            add_data_entry(row, faulty_sense_key)\n",
    "        \n",
    "        if row.lemma in evaluation_data:\n",
    "            evaluation_data[row.lemma][\"X_data_1\"].append(X_data_1)\n",
    "            evaluation_data[row.lemma][\"X_data_2\"].append(X_data_2)\n",
    "            evaluation_data[row.lemma][\"y_data\"].append(y_data)\n",
    "        else:\n",
    "            evaluation_data[row.lemma] = {}\n",
    "            evaluation_data[row.lemma][\"X_data_1\"] = X_data_1\n",
    "            evaluation_data[row.lemma][\"X_data_2\"] = X_data_2\n",
    "            evaluation_data[row.lemma][\"y_data\"] = y_data\n",
    "\n",
    "    return evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lemmas to evaluate for:\ndict_keys(['lead.v', 'extend.v', 'regular.a', 'see.v', 'position.n', 'find.v', 'force.n', 'hold.v', 'build.v', 'serve.v', 'keep.v', 'bad.a', 'national.a', 'point.n', 'order.n', 'time.n', 'physical.a', 'professional.a', 'place.n', 'case.n', 'line.n', 'security.n', 'follow.v', 'common.a', 'critical.a', 'positive.a', 'life.n', 'bring.v', 'major.a', 'active.a'])\n\nEvaluation samples per lemma:\n{'lead.v': 524, 'extend.v': 528, 'regular.a': 392, 'see.v': 1337, 'position.n': 446, 'find.v': 462, 'force.n': 556, 'hold.v': 630, 'build.v': 525, 'serve.v': 610, 'keep.v': 1081, 'bad.a': 356, 'national.a': 451, 'point.n': 419, 'order.n': 403, 'time.n': 405, 'physical.a': 387, 'professional.a': 377, 'place.n': 382, 'case.n': 469, 'line.n': 1129, 'security.n': 433, 'follow.v': 664, 'common.a': 358, 'critical.a': 310, 'positive.a': 260, 'life.n': 419, 'bring.v': 496, 'major.a': 311, 'active.a': 282}\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = create_evaluation_sentence_pair_data(test_data)\n",
    "print(f\"Lemmas to evaluate for:\")\n",
    "print(evaluation_data.keys())\n",
    "print(\"\")\n",
    "nbr_of_evaluation_samples_per_lemma = {lemma: len(evaluation_data[lemma][\"X_data_1\"]) for lemma in evaluation_data.keys()}\n",
    "print(f\"Evaluation samples per lemma:\")\n",
    "print(nbr_of_evaluation_samples_per_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"evaluation_data\": evaluation_data})"
   ]
  }
 ]
}