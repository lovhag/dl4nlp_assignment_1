{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('dl4nlp_assignment_1': conda)",
   "display_name": "Python 3.8.5 64-bit ('dl4nlp_assignment_1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dfc50ec6eac23905ec9d0de14b95fb04de7a27191c56780f2104afc692b71c20"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model 1: Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import help_functions\n",
    "import data_processor"
   ]
  },
  {
   "source": [
    "## STRUCTURE\n",
    "1. Add the different word senses to the texts.\n",
    "2. Build a vocabulary.\n",
    "3. Build the model with embedding and Attention.\n",
    "5. Train on the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0. BASIC HELP FUNCTIONS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_file(data):\n",
    "    print(\"Given data with head:\")\n",
    "    print(data.head())\n",
    "    should_save = input(\"Do you wish to save it? (y/n): \")\n",
    "    if should_save == \"y\":\n",
    "        filename = input(\"Specify the filename to save to: \")\n",
    "        data.to_csv(filename, index=False)\n",
    "        print(\"Saved data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file():\n",
    "    should_load = input(\"Do you wish to load data from a file? (y/n): \")\n",
    "    if should_load == \"y\":\n",
    "        filename = input(\"Specify the filename to load from: \")\n",
    "        data = pd.read_csv(filename)\n",
    "        return data"
   ]
  },
  {
   "source": [
    "## 1. Add the different word senses to the texts."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            sense_key       lemma  word_position  \\\n",
       "0      keep%2:42:07::      keep.v             15   \n",
       "1  national%3:01:00::  national.a             25   \n",
       "2     build%2:31:03::     build.v             38   \n",
       "3     place%1:04:00::     place.n             36   \n",
       "4  position%1:04:01::  position.n             76   \n",
       "\n",
       "                                                text  \n",
       "0  Action by the Committee In pursuance of its ma...  \n",
       "1  A guard of honour stood in formation in honour...  \n",
       "2  The principle that statistics should be timely...  \n",
       "3  Again , he appealed for additional support for...  \n",
       "4  Also , the IAEA has the lowest number of women...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sense_key</th>\n      <th>lemma</th>\n      <th>word_position</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>keep%2:42:07::</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>Action by the Committee In pursuance of its ma...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>national%3:01:00::</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>A guard of honour stood in formation in honour...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>build%2:31:03::</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>The principle that statistics should be timely...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>place%1:04:00::</td>\n      <td>place.n</td>\n      <td>36</td>\n      <td>Again , he appealed for additional support for...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>position%1:04:01::</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>Also , the IAEA has the lowest number of women...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "filename = \"/Users/lovhag/Projects/dl4nlp_assignment_1/a1_data/wsd_train.txt\"\n",
    "data = pd.read_table(filename,header=None,names=['sense_key', 'lemma', 'word_position', 'text'])\n",
    "#data = data.iloc[0:10]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       lemma  word_pos  \\\n",
       "0  Action by the Committee In pursuance of its ma...      keep.v        15   \n",
       "1  A guard of honour stood in formation in honour...  national.a        25   \n",
       "2  The principle that statistics should be timely...     build.v        38   \n",
       "3  Again , he appealed for additional support for...     place.n        36   \n",
       "4  Also , the IAEA has the lowest number of women...  position.n        76   \n",
       "\n",
       "            sense_key  \n",
       "0      keep%2:42:07::  \n",
       "1  national%3:01:00::  \n",
       "2     build%2:31:03::  \n",
       "3     place%1:04:00::  \n",
       "4  position%1:04:01::  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>word_pos</th>\n      <th>sense_key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Action by the Committee In pursuance of its ma...</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>keep%2:42:07::</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A guard of honour stood in formation in honour...</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>national%3:01:00::</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The principle that statistics should be timely...</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>build%2:31:03::</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Again , he appealed for additional support for...</td>\n      <td>place.n</td>\n      <td>36</td>\n      <td>place%1:04:00::</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also , the IAEA has the lowest number of women...</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>position%1:04:01::</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "processor = data_processor.DataProcessor(data.text.to_list(), data.lemma.to_list(), data.word_position.to_list(), data.sense_key.to_list())\n",
    "processor.get_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       lemma  word_pos  \\\n",
       "0  Action by the Committee In pursuance of its ma...      keep.v        15   \n",
       "1  A guard of honour stood in formation in honour...  national.a        25   \n",
       "2  The principle that statistics should be timely...     build.v        38   \n",
       "3  Again , he appealed for additional support for...     place.n        37   \n",
       "4  Also , the IAEA has the lowest number of women...  position.n        76   \n",
       "\n",
       "            sense_key  \n",
       "0      keep%2:42:07::  \n",
       "1  national%3:01:00::  \n",
       "2     build%2:31:03::  \n",
       "3     place%1:04:00::  \n",
       "4  position%1:04:01::  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>word_pos</th>\n      <th>sense_key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Action by the Committee In pursuance of its ma...</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>keep%2:42:07::</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A guard of honour stood in formation in honour...</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>national%3:01:00::</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The principle that statistics should be timely...</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>build%2:31:03::</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Again , he appealed for additional support for...</td>\n      <td>place.n</td>\n      <td>37</td>\n      <td>place%1:04:00::</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also , the IAEA has the lowest number of women...</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>position%1:04:01::</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "processor.fix_period_spaces_and_word_index_in_data()\n",
    "processor.fix_quotations_and_word_index_in_data()\n",
    "processor.get_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       lemma  word_pos  \\\n",
       "0  Action by the Committee In pursuance of its ma...      keep.v        15   \n",
       "1  A guard of honour stood in formation in honour...  national.a        25   \n",
       "2  The principle that statistics should be timely...     build.v        38   \n",
       "3  Again , he appealed for additional support for...     place.n        37   \n",
       "4  Also , the IAEA has the lowest number of women...  position.n        76   \n",
       "\n",
       "            sense_key                                    lemmatized_text  \n",
       "0      keep%2:42:07::  action by the Committee in pursuance of -PRON-...  \n",
       "1  national%3:01:00::  a guard of honour stand in formation in honour...  \n",
       "2     build%2:31:03::  the principle that statistic should be timely ...  \n",
       "3     place%1:04:00::  again , -PRON- appeal for additional support f...  \n",
       "4  position%1:04:01::  also , the IAEA have the low number of woman p...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>word_pos</th>\n      <th>sense_key</th>\n      <th>lemmatized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Action by the Committee In pursuance of its ma...</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>keep%2:42:07::</td>\n      <td>action by the Committee in pursuance of -PRON-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A guard of honour stood in formation in honour...</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>national%3:01:00::</td>\n      <td>a guard of honour stand in formation in honour...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The principle that statistics should be timely...</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>build%2:31:03::</td>\n      <td>the principle that statistic should be timely ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Again , he appealed for additional support for...</td>\n      <td>place.n</td>\n      <td>37</td>\n      <td>place%1:04:00::</td>\n      <td>again , -PRON- appeal for additional support f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also , the IAEA has the lowest number of women...</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>position%1:04:01::</td>\n      <td>also , the IAEA have the low number of woman p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "processor.lemmatize_text_in_data()\n",
    "processor.get_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lemmas_matching(row, text_col, word_pos_col):\n",
    "    text_splitted = row[text_col].split(' ')\n",
    "    lemma_in_text = text_splitted[row[word_pos_col]]\n",
    "    return lemma_in_text == row.lemma[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_matching_col = processor.get_data().apply(lambda x: check_lemmas_matching(x, 'lemmatized_text', 'word_pos'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45       False\n",
       "61       False\n",
       "93       False\n",
       "172      False\n",
       "215      False\n",
       "         ...  \n",
       "75902    False\n",
       "75903    False\n",
       "75958    False\n",
       "75967    False\n",
       "76048    False\n",
       "Length: 1979, dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "lemmas_matching_col[lemmas_matching_col == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_at_data_example(data, show_index):\n",
    "    row = data.iloc[show_index]\n",
    "    print(f\"lemma: {row.lemma}\")\n",
    "    print(\"\")\n",
    "    print(f\"original: {row.text}\")\n",
    "    print(\"\")\n",
    "    print(f\"lemmatized: {row.lemmatized_text}\")\n",
    "    print(\"\")\n",
    "    text_splitted = row.text.split(' ')\n",
    "    lemmatized_text_splitted = row.lemmatized_text.split(' ')\n",
    "    print(f\"lemma in original: {text_splitted[row.word_pos]}\")\n",
    "    print(f\"lemma in lemmatized: {lemmatized_text_splitted[row.word_pos]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lemma: time.n\n\noriginal: To begin with , South-North dialogue encompasses a broad field , from political and diplomatic exchanges through trade , poverty eradication , investment , technology , industrialization , capacity-building and financing for development to the empowering of people . A recent cover story in Time magazine featured our esteemed Secretary-General . It called him a dreamer .\n\nlemmatized: to begin with , south-north dialogue encompass a broad field , from political and diplomatic exchange through trade , poverty eradication , investment , technology , industrialization , capacity-building and financing for development to the empowering of people . a recent cover story in Time magazine feature -PRON- esteemed secretary-general . -PRON- call -PRON- a dreamer .\n\nlemma in original: Time\nlemma in lemmatized: Time\n"
     ]
    }
   ],
   "source": [
    "look_at_data_example(processor.get_data(), 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       lemma  word_pos  \\\n",
       "0  Action by the Committee In pursuance of its ma...      keep.v        15   \n",
       "1  A guard of honour stood in formation in honour...  national.a        25   \n",
       "2  The principle that statistics should be timely...     build.v        38   \n",
       "3  Again , he appealed for additional support for...     place.n        37   \n",
       "4  Also , the IAEA has the lowest number of women...  position.n        76   \n",
       "\n",
       "            sense_key                                    lemmatized_text  \\\n",
       "0      keep%2:42:07::  action by the Committee in pursuance of -PRON-...   \n",
       "1  national%3:01:00::  a guard of honour stand in formation in honour...   \n",
       "2     build%2:31:03::  the principle that statistic should be timely ...   \n",
       "3     place%1:04:00::  again , -PRON- appeal for additional support f...   \n",
       "4  position%1:04:01::  also , the IAEA have the low number of woman p...   \n",
       "\n",
       "  sensed_lemma                                 sense_encoded_text  \n",
       "0       keep_1  [action, by, the, Committee, in, pursuance, of...  \n",
       "1   national_1  [a, guard, of, honour, stand, in, formation, i...  \n",
       "2      build_1  [the, principle, that, statistic, should, be, ...  \n",
       "3      place_1  [again, ,, -PRON-, appeal, for, additional, su...  \n",
       "4   position_1  [also, ,, the, IAEA, have, the, low, number, o...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>word_pos</th>\n      <th>sense_key</th>\n      <th>lemmatized_text</th>\n      <th>sensed_lemma</th>\n      <th>sense_encoded_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Action by the Committee In pursuance of its ma...</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>keep%2:42:07::</td>\n      <td>action by the Committee in pursuance of -PRON-...</td>\n      <td>keep_1</td>\n      <td>[action, by, the, Committee, in, pursuance, of...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A guard of honour stood in formation in honour...</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>national%3:01:00::</td>\n      <td>a guard of honour stand in formation in honour...</td>\n      <td>national_1</td>\n      <td>[a, guard, of, honour, stand, in, formation, i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The principle that statistics should be timely...</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>build%2:31:03::</td>\n      <td>the principle that statistic should be timely ...</td>\n      <td>build_1</td>\n      <td>[the, principle, that, statistic, should, be, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Again , he appealed for additional support for...</td>\n      <td>place.n</td>\n      <td>37</td>\n      <td>place%1:04:00::</td>\n      <td>again , -PRON- appeal for additional support f...</td>\n      <td>place_1</td>\n      <td>[again, ,, -PRON-, appeal, for, additional, su...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also , the IAEA has the lowest number of women...</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>position%1:04:01::</td>\n      <td>also , the IAEA have the low number of woman p...</td>\n      <td>position_1</td>\n      <td>[also, ,, the, IAEA, have, the, low, number, o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "processor.sense_encode_text_in_data('lemmatized_text')\n",
    "processor.get_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = processor.get_data()"
   ]
  },
  {
   "source": [
    "Potentially check some of the less frequent lemmas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       lemma  word_pos  \\\n",
       "0  Action by the Committee In pursuance of its ma...      keep.v        15   \n",
       "1  A guard of honour stood in formation in honour...  national.a        25   \n",
       "2  The principle that statistics should be timely...     build.v        38   \n",
       "3  Again , he appealed for additional support for...     place.n        37   \n",
       "4  Also , the IAEA has the lowest number of women...  position.n        76   \n",
       "\n",
       "            sense_key                                    lemmatized_text  \\\n",
       "0      keep%2:42:07::  action by the Committee in pursuance of -PRON-...   \n",
       "1  national%3:01:00::  a guard of honour stand in formation in honour...   \n",
       "2     build%2:31:03::  the principle that statistic should be timely ...   \n",
       "3     place%1:04:00::  again , -PRON- appeal for additional support f...   \n",
       "4  position%1:04:01::  also , the IAEA have the low number of woman p...   \n",
       "\n",
       "  sensed_lemma                                 sense_encoded_text  \n",
       "0       keep_1  [action, by, the, Committee, in, pursuance, of...  \n",
       "1   national_1  [a, guard, of, honour, stand, in, formation, i...  \n",
       "2      build_1  [the, principle, that, statistic, should, be, ...  \n",
       "3      place_1  [again, ,, -PRON-, appeal, for, additional, su...  \n",
       "4   position_1  [also, ,, the, IAEA, have, the, low, number, o...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>word_pos</th>\n      <th>sense_key</th>\n      <th>lemmatized_text</th>\n      <th>sensed_lemma</th>\n      <th>sense_encoded_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Action by the Committee In pursuance of its ma...</td>\n      <td>keep.v</td>\n      <td>15</td>\n      <td>keep%2:42:07::</td>\n      <td>action by the Committee in pursuance of -PRON-...</td>\n      <td>keep_1</td>\n      <td>[action, by, the, Committee, in, pursuance, of...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A guard of honour stood in formation in honour...</td>\n      <td>national.a</td>\n      <td>25</td>\n      <td>national%3:01:00::</td>\n      <td>a guard of honour stand in formation in honour...</td>\n      <td>national_1</td>\n      <td>[a, guard, of, honour, stand, in, formation, i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The principle that statistics should be timely...</td>\n      <td>build.v</td>\n      <td>38</td>\n      <td>build%2:31:03::</td>\n      <td>the principle that statistic should be timely ...</td>\n      <td>build_1</td>\n      <td>[the, principle, that, statistic, should, be, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Again , he appealed for additional support for...</td>\n      <td>place.n</td>\n      <td>37</td>\n      <td>place%1:04:00::</td>\n      <td>again , -PRON- appeal for additional support f...</td>\n      <td>place_1</td>\n      <td>[again, ,, -PRON-, appeal, for, additional, su...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also , the IAEA has the lowest number of women...</td>\n      <td>position.n</td>\n      <td>76</td>\n      <td>position%1:04:01::</td>\n      <td>also , the IAEA have the low number of woman p...</td>\n      <td>position_1</td>\n      <td>[also, ,, the, IAEA, have, the, low, number, o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['action',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Committee',\n",
       " 'in',\n",
       " 'pursuance',\n",
       " 'of',\n",
       " '-PRON-',\n",
       " 'mandate',\n",
       " ',',\n",
       " 'the',\n",
       " 'Committee',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'keep_1',\n",
       " 'under',\n",
       " 'review',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'relate',\n",
       " 'to',\n",
       " 'the',\n",
       " 'question',\n",
       " 'of',\n",
       " 'Palestine',\n",
       " 'and',\n",
       " 'participate',\n",
       " 'in',\n",
       " 'relevant',\n",
       " 'meeting',\n",
       " 'of',\n",
       " 'the',\n",
       " 'General',\n",
       " 'Assembly',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Security',\n",
       " 'Council',\n",
       " '.',\n",
       " 'the',\n",
       " 'Committee',\n",
       " 'will',\n",
       " 'also',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'monitor',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'and',\n",
       " 'draw',\n",
       " 'the',\n",
       " 'attention',\n",
       " 'of',\n",
       " 'the',\n",
       " 'international',\n",
       " 'community',\n",
       " 'to',\n",
       " 'urgent',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'occupied',\n",
       " 'Palestinian',\n",
       " 'Territory',\n",
       " ',',\n",
       " 'include',\n",
       " 'East',\n",
       " 'Jerusalem',\n",
       " ',',\n",
       " 'require',\n",
       " 'international',\n",
       " 'action',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "data.iloc[0].sense_encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Reiterating its full support for the efforts of the Secretary-General , the African Union and regional actors to find solutions to armed conflicts in the region , Reaffirming that any attempt at destabilization through violent means or seizing power by force is unacceptable , Reaffirming its resolutions 1325 ( 2000 ) and 1820 ( 2008 ) on women , peace and security , 1502 ( 2003 ) on the protection of humanitarian and United Nations personnel , and 1674 ( 2006 ) on the protection of civilians in armed conflict ,'"
      ]
     },
     "metadata": {},
     "execution_count": 276
    }
   ],
   "source": [
    "data = processor.get_data()\n",
    "data[data.sensed_lemma==\"force_4\"].iloc[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76049 entries, 0 to 76048\nData columns (total 7 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   text                76049 non-null  object\n 1   lemma               76049 non-null  object\n 2   word_pos            76049 non-null  int64 \n 3   sense_key           76049 non-null  object\n 4   lemmatized_text     76049 non-null  object\n 5   sensed_lemma        76049 non-null  object\n 6   sense_encoded_text  76049 non-null  object\ndtypes: int64(1), object(6)\nmemory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Given data with head:\n",
      "                                                text       lemma  word_pos  \\\n",
      "0  Action by the Committee In pursuance of its ma...      keep.v        15   \n",
      "1  A guard of honour stood in formation in honour...  national.a        25   \n",
      "2  The principle that statistics should be timely...     build.v        38   \n",
      "3  Again , he appealed for additional support for...     place.n        37   \n",
      "4  Also , the IAEA has the lowest number of women...  position.n        76   \n",
      "\n",
      "            sense_key                                    lemmatized_text  \\\n",
      "0      keep%2:42:07::  action by the Committee in pursuance of -PRON-...   \n",
      "1  national%3:01:00::  a guard of honour stand in formation in honour...   \n",
      "2     build%2:31:03::  the principle that statistic should be timely ...   \n",
      "3     place%1:04:00::  again , -PRON- appeal for additional support f...   \n",
      "4  position%1:04:01::  also , the IAEA have the low number of woman p...   \n",
      "\n",
      "  sensed_lemma                                 sense_encoded_text  \n",
      "0       keep_1  [action, by, the, Committee, in, pursuance, of...  \n",
      "1   national_1  [a, guard, of, honour, stand, in, formation, i...  \n",
      "2      build_1  [the, principle, that, statistic, should, be, ...  \n",
      "3      place_1  [again, ,, -PRON-, appeal, for, additional, su...  \n",
      "4   position_1  [also, ,, the, IAEA, have, the, low, number, o...  \n",
      "Saved data!\n"
     ]
    }
   ],
   "source": [
    "save_data_to_file(processor.get_data())"
   ]
  },
  {
   "source": [
    "## 2. Build the vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8420"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "voc = help_functions.Vocabulary(min_word_freq=22, include_unknown=True, lower=True, character=False)\n",
    "voc.build(processor.get_data().sense_encoded_text)\n",
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8312"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "voc.stoi['line_9']"
   ]
  },
  {
   "source": [
    "## 2.* Create data fitting to the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequence, max_sequence_len):\n",
    "    return sequence+[voc.get_pad_idx()]*(max_sequence_len-len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(data, max_sequence_len=None):\n",
    "    def build_X_elem(X):\n",
    "        X_elem = voc.encode([X])[0]\n",
    "        if max_sequence_len:\n",
    "            return pad_sequence(X_elem, max_sequence_len)\n",
    "        return X_elem\n",
    "\n",
    "    sense_dict = help_functions.build_sense_dict(data.lemma.to_list(), data.sense_key.to_list())\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        X_data.append(build_X_elem(row.sense_encoded_text))\n",
    "        y_data.append([1])\n",
    "\n",
    "        # append faulty sense examples\n",
    "        available_senses = list(sense_dict[row.lemma].keys())\n",
    "        available_senses.remove(row.sense_key)\n",
    "        for sense in available_senses:\n",
    "            faulty_text = row.sense_encoded_text.copy()\n",
    "            #print(faulty_text)\n",
    "            faulty_text[row.word_pos] = row.lemma[:-2]+\"_\"+str(sense_dict[row.lemma][sense])\n",
    "            X_data.append(build_X_elem(faulty_text.copy()))\n",
    "            y_data.append([0])\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "source": [
    "import numpy as np\n",
    "v = [0,1,2]\n",
    "np.random.choice(len(v),1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_equal_training_data(data, max_sequence_len=None):\n",
    "    def build_X_elem(X):\n",
    "        X_elem = voc.encode([X])[0]\n",
    "        if max_sequence_len:\n",
    "            return pad_sequence(X_elem, max_sequence_len)\n",
    "        return X_elem\n",
    "\n",
    "    sense_dict = help_functions.build_sense_dict(data.lemma.to_list(), data.sense_key.to_list())\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        X_data.append(build_X_elem(row.sense_encoded_text))\n",
    "        y_data.append([1])\n",
    "\n",
    "        # append one faulty sense example\n",
    "        available_senses = list(sense_dict[row.lemma].keys())\n",
    "        available_senses.remove(row.sense_key)\n",
    "        faulty_sense = available_senses[np.random.choice(len(v), 1)[0]]\n",
    "        faulty_text = row.sense_encoded_text.copy()\n",
    "        faulty_text[row.word_pos] = row.lemma[:-2]+\"_\"+str(sense_dict[row.lemma][faulty_sense])\n",
    "        X_data.append(build_X_elem(faulty_text.copy()))\n",
    "        y_data.append([0])\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_sequence_length(sequence_list):\n",
    "    max_sequence_len = 0\n",
    "    for sequence in sequence_list:\n",
    "        if len(sequence) > max_sequence_len:\n",
    "            max_sequence_len = len(sequence)\n",
    "    return max_sequence_len"
   ]
  },
  {
   "source": [
    "Max sequence length of data seems to be 283."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "find_max_sequence_length(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = create_training_data(data, 283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of samples: 152098\nSequence length per sample: 283\n"
     ]
    }
   ],
   "source": [
    "X_data_eq, y_data_eq = create_equal_training_data(data, 283)\n",
    "print(f'Number of samples: {len(y_data_eq)}')\n",
    "print(f'Sequence length per sample: {len(X_data_eq[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_with_pickle(data_dict):\n",
    "    pre_filename = input(\"Specify which prefix filename you wish to save X_data and y_data to: \")\n",
    "    if pre_filename:\n",
    "        for key, value in data_dict.items():\n",
    "            filename = pre_filename+\"_\"+key+\".pickle\"\n",
    "            with open(filename, \"wb\") as fp:   #Pickling\n",
    "                pickle.dump(value, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"X_data\": X_data, \"y_data\": y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"X_data_eq\": X_data_eq, \"y_data_eq\": y_data_eq})"
   ]
  },
  {
   "source": [
    "Split into train and validation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eq, X_test_eq, y_train_eq, y_test_eq = train_test_split(X_data_eq, y_data_eq, test_size=0.33, random_state=42)\n",
    "save_data_with_pickle({\"X_train_eq\": X_train_eq, \"X_test_eq\": X_test_eq, \"y_train_eq\": y_train_eq, \"y_test_eq\": y_test_eq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle({\"voc\": voc})"
   ]
  },
  {
   "source": [
    "## 3. Build the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Get the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(filename):\n",
    "    with open(filename, \"rb\") as load_file:\n",
    "        return pickle.load(load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_pickle_data(\"saved_data/splitted_X_train_eq.pickle\")\n",
    "X_test = load_pickle_data(\"saved_data/splitted_X_test_eq.pickle\")\n",
    "y_train = load_pickle_data(\"saved_data/splitted_y_train_eq.pickle\")\n",
    "y_test = load_pickle_data(\"saved_data/splitted_y_test_eq.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Using', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training samples: 101905\nNumber of test samples: 50193\n\nSequence length per sample: 283\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {len(y_train)}')\n",
    "print(f'Number of test samples: {len(y_test)}')\n",
    "print(\"\")\n",
    "print(f'Sequence length per sample: {len(X_train[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(x, y, batch_size):\n",
    "    random_indices = torch.randperm(len(x))\n",
    "    for i in range(0, len(x) - batch_size + 1, batch_size):\n",
    "        indices = random_indices[i:i+batch_size]\n",
    "        yield x[indices].to(device), y[indices].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
    "        in the sequence. The positional encodings have the same dimension as\n",
    "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
    "        functions of different frequencies.\n",
    "    .. math::\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAttentionModel(nn.Module):\n",
    "    \"\"\"My Attention model, based on the Transformer encoder.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, max_seq_len, num_heads, dim_feedforward, num_layers, dropout=0.5):\n",
    "        super(MyAttentionModel, self).__init__()\n",
    "        try:\n",
    "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        except:\n",
    "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout=0.1, max_len=max_seq_len)\n",
    "        encoder_layers = TransformerEncoderLayer(embedding_dim, num_heads, dim_feedforward, dropout)\n",
    "        # output shape (batch_size, max_seq_len, embedding_dim)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers) \n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.decoder = nn.Linear(embedding_dim*max_seq_len, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.weight)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, src, has_mask=True):\n",
    "        if has_mask:\n",
    "            device = src.device\n",
    "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "                self.src_mask = mask\n",
    "        else:\n",
    "            self.src_mask = None\n",
    "\n",
    "        #print(f\"Input shape: {src.shape}\")\n",
    "        src = self.encoder(src) * math.sqrt(self.embedding_dim)\n",
    "        #print(f\"Embedded shape: {src.shape}\")\n",
    "        src = self.pos_encoder(src)\n",
    "        #print(f\"Positional encoding shape: {src.shape}\")\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        #print(f\"Transformer encoder output shape: {output.shape}\")\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        #print(f\"Reshaped output shape: {output.shape}\")\n",
    "        output = self.decoder(output)\n",
    "        #print(f\"Decoder output shape: {output.shape}\")\n",
    "        #print(h)\n",
    "        return F.log_softmax(output, dim=-1)"
   ]
  },
  {
   "source": [
    "## Train the transformer!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, X_test, y_train, y_test, n_epochs=1, batch_size=100, lr=0.001, max_samples=None, weight_true=0.5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    min_ppl = float('inf')\n",
    "    for t in range(n_epochs):\n",
    "        model.train()\n",
    "        loss_fun = F.binary_cross_entropy\n",
    "\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        nbr_train_batches = 0\n",
    "        for bx, by in batchify(X_train, y_train, batch_size):\n",
    "            nbr_train_batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(bx)\n",
    "            sample_weight = (by.eq(1)*weight_true)+(by.eq(0)*(1-weight_true))\n",
    "            #print(sample_weight)\n",
    "            loss = loss_fun(output, by.type(torch.FloatTensor), weight=sample_weight)\n",
    "            loss_sum += loss.item()\n",
    "            accuracy = (output.eq(by)).sum()\n",
    "            accuracy_sum += accuracy\n",
    "\n",
    "            if max_samples and updater.n >= max_samples:\n",
    "                break\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = loss_sum/(nbr_train_batches*batch_size)\n",
    "        train_acc = torch.true_divide(accuracy_sum,(nbr_train_batches*batch_size))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_sum = 0\n",
    "            accuracy_sum = 0\n",
    "            nbr_test_batches = 0\n",
    "            for bx, by in batchify(X_test, y_test, batch_size):\n",
    "                nbr_test_batches += 1\n",
    "                output = model.forward(bx)\n",
    "                sample_weight = (by.eq(1)*weight_true)+(by.eq(0)*(1-weight_true))\n",
    "                loss = loss_fun(output, by.type(torch.FloatTensor), weight=sample_weight)\n",
    "                loss_sum += loss.item()\n",
    "                accuracy = (output.eq(by)).sum()\n",
    "                accuracy_sum += accuracy\n",
    "        test_loss = loss_sum/(nbr_test_batches*batch_size)\n",
    "        test_acc = torch.true_divide(accuracy_sum,(nbr_test_batches*batch_size))\n",
    "\n",
    "        print(f'epoch {t} | train loss {train_loss} | train acc {train_acc} | validation loss {test_loss} | validation acc {test_acc}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_subset(sub_percentage, X_train, X_test, y_train, y_test):\n",
    "    train_sub_size = int(sub_percentage*len(y_train))\n",
    "    test_sub_size = int(sub_percentage*len(y_test))\n",
    "\n",
    "    X_train_sub = X_train[:train_sub_size]\n",
    "    X_test_sub = X_test[:test_sub_size]\n",
    "    y_train_sub = y_train[:train_sub_size]\n",
    "    y_test_sub = y_test[:test_sub_size]\n",
    "\n",
    "    return X_train_sub, X_test_sub, y_train_sub, y_test_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label: [0]\n['___BOS___', 'the', 'foreign', 'ministers', 'of', 'egypt', ',', 'ireland', ',', 'mexico', ',', 'new', 'zealand', ',', 'south', 'africa', ',', 'sweden', 'and', 'brazil', 'meet', 'at', 'the', 'fifty-eighth', 'session', 'of', 'the', 'united', 'nations', 'general', 'assembly', 'to', 'review', 'development', 'on', 'nuclear', 'disarmament', 'and', 'to', 'renew', '-pron-', 'commitment', 'to', 'achieve', 'a', 'world', 'free', 'from', 'nuclear', 'weapon', '.', 'the', 'ministers', 'pay', 'tribute', 'to', 'the', 'memory', 'of', '___UNKNOWN___', '___UNKNOWN___', ',', 'foreign', 'minister', 'of', 'sweden', ',', 'on', 'the', 'occasion', 'of', '-pron-', 'sad', 'pass', 'away', ',', 'and', 'deplore', 'the', 'loss', 'of', 'a', 'devoted', 'colleague', 'who', 'have', 'be', 'a', 'drive', 'force_4', 'in', 'the', 'common', 'cause', '.', 'the', 'ministers', 'express', '-pron-', 'deep', 'concern', 'at', 'the', 'lack', 'of', 'progress', 'to', 'date', 'in', 'the', 'implementation', 'of', 'the', '___UNKNOWN___', 'step', 'on', 'nuclear', 'disarmament', 'to', 'which', 'all', 'state', 'party', 'to', 'the', 'treaty', 'on', 'the', 'non-proliferation', 'of', 'nuclear', 'weapons', 'agree', 'at', 'the', '2000', 'npt', 'review', 'conference', '.', '___EOS___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___', '___PAD___']\n"
     ]
    }
   ],
   "source": [
    "sample_index = 2005\n",
    "sample = [voc.itos[i] for i in data_subset[0][sample_index]]\n",
    "sample_label = data_subset[2][sample_index]\n",
    "print(f\"label: {sample_label}\")\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 | train loss 0.7985761088709677 | train acc 0.48891130089759827 | validation loss 0.771484375 | validation acc 0.5062500238418579\n",
      "epoch 1 | train loss 0.8001512096774194 | train acc 0.4879032373428345 | validation loss 0.7584635416666666 | validation acc 0.5145833492279053\n",
      "epoch 2 | train loss 0.8033014112903226 | train acc 0.4858871102333069 | validation loss 0.751953125 | validation acc 0.518750011920929\n",
      "epoch 3 | train loss 0.8048765120967742 | train acc 0.4848790466785431 | validation loss 0.7649739583333334 | validation acc 0.5104166865348816\n",
      "epoch 4 | train loss 0.8001512096774194 | train acc 0.4879032373428345 | validation loss 0.771484375 | validation acc 0.5062500238418579\n"
     ]
    }
   ],
   "source": [
    "data_subset = get_data_subset(0.01, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model = MyAttentionModel(vocab_size=len(voc), embedding_dim=32, max_seq_len=max_sequence_length, num_heads=2, dim_feedforward=32, num_layers=1, dropout=0.1).to(device)\n",
    "trained_model = train(model, torch.LongTensor(data_subset[0]), torch.LongTensor(data_subset[1]), torch.LongTensor(data_subset[2]), torch.LongTensor(data_subset[3]), n_epochs=5, batch_size=32, max_samples=None, weight_true=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 | train loss 0.7820177378144654 | train acc 0.49950864911079407 | validation loss 0.7900140224358975 | validation acc 0.4943910241127014\n",
      "epoch 1 | train loss 0.7827854756289309 | train acc 0.49901729822158813 | validation loss 0.7903270232371795 | validation acc 0.49419069290161133\n",
      "epoch 2 | train loss 0.7821712853773585 | train acc 0.49941039085388184 | validation loss 0.7893880208333334 | validation acc 0.4947916567325592\n",
      "epoch 3 | train loss 0.7827854756289309 | train acc 0.49901729822158813 | validation loss 0.7903270232371795 | validation acc 0.49419069290161133\n",
      "epoch 4 | train loss 0.7826319280660378 | train acc 0.49911555647850037 | validation loss 0.7893880208333334 | validation acc 0.4947916567325592\n"
     ]
    }
   ],
   "source": [
    "data_subset = get_data_subset(0.1, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model = MyAttentionModel(vocab_size=len(voc), embedding_dim=32, max_seq_len=max_sequence_length, num_heads=2, dim_feedforward=32, num_layers=1, dropout=0.1).to(device)\n",
    "trained_model = train(model, torch.LongTensor(data_subset[0]), torch.LongTensor(data_subset[1]), torch.LongTensor(data_subset[2]), torch.LongTensor(data_subset[3]), n_epochs=5, batch_size=32, max_samples=None, weight_true=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 | train loss 0.809601814516129 | train acc 0.4818548262119293 | validation loss 0.76171875 | validation acc 0.512499988079071\n",
      "epoch 1 | train loss 0.7922757056451613 | train acc 0.49294355511665344 | validation loss 0.76171875 | validation acc 0.512499988079071\n",
      "epoch 2 | train loss 0.8033014112903226 | train acc 0.4858871102333069 | validation loss 0.7454427083333334 | validation acc 0.5229166746139526\n",
      "epoch 3 | train loss 0.8033014112903226 | train acc 0.4858871102333069 | validation loss 0.7649739583333334 | validation acc 0.5104166865348816\n",
      "epoch 4 | train loss 0.7970010080645161 | train acc 0.48991936445236206 | validation loss 0.7584635416666666 | validation acc 0.5145833492279053\n",
      "epoch 5 | train loss 0.8001512096774194 | train acc 0.4879032373428345 | validation loss 0.76171875 | validation acc 0.512499988079071\n",
      "epoch 6 | train loss 0.7985761088709677 | train acc 0.48891130089759827 | validation loss 0.7584635416666666 | validation acc 0.5145833492279053\n",
      "epoch 7 | train loss 0.8048765120967742 | train acc 0.4848790466785431 | validation loss 0.7682291666666666 | validation acc 0.5083333253860474\n",
      "epoch 8 | train loss 0.8033014112903226 | train acc 0.4858871102333069 | validation loss 0.7649739583333334 | validation acc 0.5104166865348816\n",
      "epoch 9 | train loss 0.8033014112903226 | train acc 0.4858871102333069 | validation loss 0.751953125 | validation acc 0.518750011920929\n"
     ]
    }
   ],
   "source": [
    "data_subset = get_data_subset(0.01, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model = MyAttentionModel(vocab_size=len(voc), embedding_dim=32, max_seq_len=max_sequence_length, num_heads=2, dim_feedforward=32, num_layers=1, dropout=0.1).to(device)\n",
    "trained_model = train(model, torch.LongTensor(data_subset[0]), torch.LongTensor(data_subset[1]), torch.LongTensor(data_subset[2]), torch.LongTensor(data_subset[3]), n_epochs=10, batch_size=32, max_samples=None, weight_true=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 | train loss 0.3897662138819096 | train acc 0.5010992288589478 | validation loss 0.39243114237882654 | validation acc 0.4976881444454193\n",
      "epoch 1 | train loss 0.3897585461487123 | train acc 0.5011090636253357 | validation loss 0.392337721221301 | validation acc 0.49780771136283875\n",
      "epoch 2 | train loss 0.389781549348304 | train acc 0.5010796189308167 | validation loss 0.39238443180006377 | validation acc 0.49774792790412903\n",
      "epoch 3 | train loss 0.3897508784155151 | train acc 0.5011188983917236 | validation loss 0.3924155721859056 | validation acc 0.4977080821990967\n",
      "epoch 4 | train loss 0.389781549348304 | train acc 0.5010796189308167 | validation loss 0.39238443180006377 | validation acc 0.49774792790412903\n",
      "epoch 5 | train loss 0.3897585461487123 | train acc 0.5011090636253357 | validation loss 0.39236886160714285 | validation acc 0.4977678656578064\n",
      "epoch 6 | train loss 0.3897738816151068 | train acc 0.5010894536972046 | validation loss 0.392337721221301 | validation acc 0.49780771136283875\n",
      "epoch 7 | train loss 0.3897508784155151 | train acc 0.5011188983917236 | validation loss 0.3924000019929847 | validation acc 0.49772799015045166\n",
      "epoch 8 | train loss 0.389781549348304 | train acc 0.5010796189308167 | validation loss 0.39236886160714285 | validation acc 0.4977678656578064\n",
      "epoch 9 | train loss 0.3897355429491206 | train acc 0.5011385083198547 | validation loss 0.3924000019929847 | validation acc 0.49772799015045166\n",
      "epoch 10 | train loss 0.3897662138819096 | train acc 0.5010992288589478 | validation loss 0.39238443180006377 | validation acc 0.49774792790412903\n",
      "epoch 11 | train loss 0.3897662138819096 | train acc 0.5010992288589478 | validation loss 0.39238443180006377 | validation acc 0.49774792790412903\n",
      "epoch 12 | train loss 0.3897662138819096 | train acc 0.5010992288589478 | validation loss 0.3923532914142219 | validation acc 0.4977877736091614\n",
      "epoch 13 | train loss 0.3897585461487123 | train acc 0.5011090636253357 | validation loss 0.39236886160714285 | validation acc 0.4977678656578064\n",
      "epoch 14 | train loss 0.3897508784155151 | train acc 0.5011188983917236 | validation loss 0.39243114237882654 | validation acc 0.4976881444454193\n",
      "epoch 15 | train loss 0.38978921708150127 | train acc 0.5010697841644287 | validation loss 0.392337721221301 | validation acc 0.49780771136283875\n",
      "epoch 16 | train loss 0.3897968848146985 | train acc 0.5010600090026855 | validation loss 0.39236886160714285 | validation acc 0.4977678656578064\n",
      "epoch 17 | train loss 0.389781549348304 | train acc 0.5010796189308167 | validation loss 0.39238443180006377 | validation acc 0.49774792790412903\n",
      "epoch 18 | train loss 0.38978921708150127 | train acc 0.5010697841644287 | validation loss 0.39236886160714285 | validation acc 0.4977678656578064\n",
      "epoch 19 | train loss 0.3897662138819096 | train acc 0.5010992288589478 | validation loss 0.39236886160714285 | validation acc 0.4977678656578064\n"
     ]
    }
   ],
   "source": [
    "data_subset = get_data_subset(1, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model = MyAttentionModel(vocab_size=len(voc), embedding_dim=32, max_seq_len=max_sequence_length, num_heads=4, dim_feedforward=32, num_layers=1, dropout=0).to(device)\n",
    "trained_model = train(model, torch.LongTensor(data_subset[0]), torch.LongTensor(data_subset[1]), torch.LongTensor(data_subset[2]), torch.LongTensor(data_subset[3]), n_epochs=20, batch_size=64, lr=0.001, max_samples=None, weight_true=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'get_data_subset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-797fea295c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyAttentionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_feedforward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_data_subset' is not defined"
     ]
    }
   ],
   "source": [
    "data_subset = get_data_subset(1, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model = MyAttentionModel(vocab_size=len(voc), embedding_dim=32, max_seq_len=max_sequence_length, num_heads=4, dim_feedforward=32, num_layers=1, dropout=0).to(device)\n",
    "trained_model = train(model, torch.LongTensor(data_subset[0]), torch.LongTensor(data_subset[1]), torch.LongTensor(data_subset[2]), torch.LongTensor(data_subset[3]), n_epochs=20, batch_size=64, lr=0.0001, max_samples=None, weight_true=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MyAttentionModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=2, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Embedding(8420, 16)\n",
       "  (decoder): Linear(in_features=4528, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 238
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8650"
      ]
     },
     "metadata": {},
     "execution_count": 239
    }
   ],
   "source": [
    "nbr_params = 0\n",
    "for parameter in model.parameters():\n",
    "    nbr_params = nbr_params + len(parameter)\n",
    "nbr_params"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}